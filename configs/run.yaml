# General
data_dir: data/samples
exps_path: data/exps
embedding_dir: data/embeddings
gpu_config: configs/gpu_config.json
cuda: 0
seed: 0
flip_p: 0.5
load_exp_path: /home/user/Documents/octopi-v2/data/exps/2024_12_25_23_02_40_train_llm_test_reason_debug

# Run components
train_encoder: False
test_encoder: False
train_llm: True
train_llm_peft: False
reason_llm: False

# Encoder
use_clip: openai/clip-vit-large-patch14
# use_clip: openai/clip-vit-large-patch14-336
frame_size: 224
adapter_lr: 0.0005
dim_context_vision: 1024
residual_ratio: 0.5
visualize_bins: 4
max_frame_length: 10
## Prompt learning
prompt_learning: True
num_context_vision: 8
prompt_depth_vision: 12
num_context_text: 6
prompt_depth_text: 12
dim_context_text: 768
gate_prior: 5.
## Training
tasks: ["property_regression", "text_contrastive", "tactile_contrastive"]
datasets: ["physiclear", "physicleardotted", "hardness", "objectfolder", "schaeffler", "schaefflerdotted"] # tvl
num_epochs: 30
batch_size: 32
num_distributed_contrastive_batches: 100
gradient_checkpointing: True

# LLM
model_type: qwen2.5-7b # llama-3.1-8b
cutoff_len: 1024
max_new_tokens: 500
offload_dir: ./
## Files
# train_files: [/home/user/Documents/octopi-v2/data/llm_qa/train_description_comparison_qa.json]
train_files : []
test_files: [/home/user/Documents/octopi-v2/data/llm_qa/train_description_comparison_qa_balls.json] # /home/user/Documents/octopi-v2/data/llm_qa/train_description_comparison_qa_fruits.json]
reasoning_files: [/home/user/Documents/octopi-v2/data/llm_qa/test_scenario_qa_1.json]
## Training
llm_lr: 0.0001
llm_gradient_accumulation_steps: 16
# warmup_steps: 0.03
per_device_batch_size: 1
## Testing
ranking_sampling: True
ranking_sampling_num: 8
ranking_temperature: 0.5
## Reasoning
scenarios: null
generate_idx: [0,1]
user_stop_idx: 2
rag: True
retrieval_object_num: 5
description_sampling_num: 1
description_temperature: 0.1
description_threshold: 0.5
reasoning_sampling_num: 16
reasoning_temperature: 0.8
reasoning_selection_type: majority_voting # best_of_n
## Projection
max_train_steps: 5000
freeze_projection: False
projection_lr: 0.0005
## LoRA
max_peft_train_steps: 1000
lora_alpha: 32
r: 32
lora_dropout: 0.05
target_modules:
  - q_proj
  - v_proj
  - k_proj
  - o_proj
  - gate_proj
  - down_proj
  - up_proj
modules_to_save:
  # - lm_head
  - embed_tokens
bias: none