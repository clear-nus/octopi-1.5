# General
data_dir: data/samples
exps_path: data/exps
gpu_config: configs/gpu_config.json
cuda: 0
seed: 0
flip_p: 0.5
load_exp_path: /home/user/Documents/octopi-s/data/exps/2025_01_04_21_23_26_train_llm_train_peft_test_reason_debug

# Encoder
use_clip: openai/clip-vit-large-patch14
frame_size: 224
adapter_lr: 0.0005
dim_context_vision: 1024
residual_ratio: 0.5
visualize_bins: 4
max_frame_length: 10
## Prompt learning
prompt_learning: True
num_context_vision: 8
num_context_sensor: 1
prompt_depth_vision: 12
num_context_text: 6
prompt_depth_text: 12
dim_context_text: 768
gate_prior: 5.
## Training
tasks: ["property_regression", "tactile_contrastive"]
datasets: ["physiclear", "physicleardotted", "hardness", "objectfolder"]
num_epochs: 30
batch_size: 32
num_distributed_contrastive_batches: 100
gradient_checkpointing: True
## Testing
target_samples_path: data/schaeffler_test_set/unseen_samples/samples

# LLM
model_type: qwen2-vl-7b
cutoff_len: 1024
max_new_tokens: 500
offload_dir: ./
## Files
train_files: []
test_files: []
reasoning_files: [/home/user/Documents/octopi-v2/data/schaeffler_demo_test/llm_qa/test_scenario_qa_unseen_samples.json]
## Training
llm_lr: 0.0001
llm_gradient_accumulation_steps: 16
per_device_batch_size: 1
## Testing
ranking_sampling: True
ranking_sampling_num: 8
ranking_temperature: 0.5
## Reasoning
scenarios: null
generate_idx: [0,1]
user_stop_idx: 2
rag: True
rag_generate_embeddings: True
rag_sample_dir: data/samples
embedding_dir: data/embeddings
rag_use_descriptions: True
retrieval_object_num: 5
reasoning_sampling_num: 16
reasoning_temperature: 0.8
reasoning_selection_type: majority_voting # best_of_n
## Projection
max_train_steps: 5000
freeze_projection: False
projection_lr: 0.0005
## LoRA
max_peft_train_steps: 1000
lora_alpha: 32
r: 32
lora_dropout: 0.05
target_modules:
  - q_proj
  - v_proj
  - k_proj
  - o_proj
  - gate_proj
  - down_proj
  - up_proj
modules_to_save:
  # - lm_head
  - embed_tokens
bias: none